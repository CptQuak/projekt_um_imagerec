{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import alexnet, AlexNet_Weights\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "\n",
    "torch.manual_seed(42069)\n",
    "# if gpu available else cpu\n",
    "device = torch.device(0) if torch.cuda.is_available() else torch.device('cpu')\n",
    "TRAIN_MEAN = [0.5036, 0.4719, 0.3897]\n",
    "TRAIN_STD = [0.2623, 0.2577, 0.2671]\n",
    "classes = ['butterfly','cat', 'chicken', 'cow', 'dog', 'elephant', 'horse', 'sheep', 'spider', 'squirrel']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zdefiniowanie operacji na kazdym obrazie w zbiorze\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(256),  #  na 256x256\n",
    "    transforms.RandomHorizontalFlip(),  # wycinamy losowy fragment 128x128\n",
    "    transforms.ToTensor(),              # obrazy zamieniamy na tensory,\n",
    "    # srednie i odchylenia po kanałach całęgo zbioru,\n",
    "    #  wyliczone wczesniej za pomocą utils.data_normalize_values\n",
    "    transforms.Normalize(TRAIN_MEAN, TRAIN_STD)\n",
    "])\n",
    "\n",
    "# loader danych z batchami\n",
    "train_data = ImageFolder(root='dataset/train/', transform=transform)\n",
    "test_data = ImageFolder(root='dataset/test/', transform=transform)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uczenie klasyfikatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1/5 epochs\n",
      "Epoch: 1, Loss 0.638, Train acc: 0.788, Test acc: 0.841\n",
      "Progress: 2/5 epochs\n",
      "Epoch: 2, Loss 0.48, Train acc: 0.839, Test acc: 0.851\n",
      "Progress: 3/5 epochs\n",
      "Epoch: 3, Loss 0.455, Train acc: 0.845, Test acc: 0.862\n",
      "Progress: 4/5 epochs\n",
      "Epoch: 4, Loss 0.43, Train acc: 0.855, Test acc: 0.869\n",
      "Progress: 5/5 epochs\n",
      "Epoch: 5, Loss 0.409, Train acc: 0.858, Test acc: 0.873\n"
     ]
    }
   ],
   "source": [
    "# RESNET18 z wagami przetrenowanymi na zbiorze IMAGENET\n",
    "alex_net_model = alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)\n",
    "# dostosowanie ostatniego layeru do problemu\n",
    "alex_net_model.classifier[6] = nn.Linear(alex_net_model.classifier[6].in_features, len(classes))\n",
    "# inicjalizacja wag w warstwie wyjsciowej\n",
    "nn.init.xavier_uniform_(alex_net_model.classifier[6].weight)\n",
    "\n",
    "\n",
    "alex_net_model = alex_net_model.to(device)\n",
    "metrics = utils.train_fine_tuning(\n",
    "    model = alex_net_model, \n",
    "    learning_rate= 5e-5, \n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    device=device, num_epochs=5, param_group=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "669bca2b7255614eb966cdff6e6d05916dced638cbe111d2c59696f28f86c1c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
